{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "junwcXoQYZAo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WZ7Chv1aYeul"
      },
      "outputs": [],
      "source": [
        "# Step 1: Download the dataset\n",
        "url = 'https://madm.dfki.de/files/sentinel/EuroSAT.zip'\n",
        "dataset_path = '/content/EuroSAT.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hAIwgLMdYtpH"
      },
      "outputs": [],
      "source": [
        "# Download the dataset with SSL verification disabled\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    response = requests.get(url, stream=True, verify=False)  # Disable SSL verification\n",
        "    with open(dataset_path, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "caA-pf_0YxSG"
      },
      "outputs": [],
      "source": [
        "# Step 2: Extract the dataset\n",
        "extract_path = '/content/EuroSAT'\n",
        "if not os.path.exists(extract_path):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "SinsxNyJY1Q9"
      },
      "outputs": [],
      "source": [
        "# Define the path to the extracted dataset\n",
        "data_path = os.path.join(extract_path, '2750')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0dQVqqMY6Pw",
        "outputId": "bcb90123-80d7-4b81-c239-185fa17afbd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subdirectories in the data path: ['River', 'SeaLake', 'PermanentCrop', 'Industrial', 'Forest', 'Residential', 'Pasture', 'AnnualCrop', 'Highway', 'HerbaceousVegetation']\n"
          ]
        }
      ],
      "source": [
        "# Verify the extracted dataset\n",
        "if not os.path.exists(data_path):\n",
        "    print(f\"The path {data_path} does not exist. Please check the extraction.\")\n",
        "else:\n",
        "    # Print the subdirectories to verify the structure\n",
        "    subdirectories = os.listdir(data_path)\n",
        "    print(\"Subdirectories in the data path:\", subdirectories)\n",
        "\n",
        "    # Step 3: Set up the data generator\n",
        "    data_generator = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        validation_split=0.2\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov4IQiPuZAzo",
        "outputId": "ebf258bf-7b72-4b00-8f75-a7ebb6586a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21600 images belonging to 10 classes.\n",
            "Found 5400 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# Generate the training data\n",
        "train_data = data_generator.flow_from_directory(\n",
        "data_path,\n",
        "target_size=(64, 64),\n",
        "batch_size=8,\n",
        "class_mode='categorical',\n",
        "subset='training',\n",
        "classes=['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
        ")\n",
        "\n",
        "\n",
        "# Generate the validation data\n",
        "test_data = data_generator.flow_from_directory(\n",
        "data_path,\n",
        "target_size=(64, 64),\n",
        "batch_size=1,\n",
        "subset='validation',\n",
        "class_mode='categorical',\n",
        "classes=['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xRAq6lOmZWsb"
      },
      "outputs": [],
      "source": [
        "CNN = keras.Sequential([\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(10,activation='softmax')\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "62JMHU59ZZcP"
      },
      "outputs": [],
      "source": [
        "CNN.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAnUcBb-ZdTm",
        "outputId": "c5f46105-68d4-41f8-84bd-327ef25af343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2700/2700 [==============================] - 60s 22ms/step - loss: 1.2853 - accuracy: 0.5149 - val_loss: 0.8812 - val_accuracy: 0.6950\n",
            "Epoch 2/20\n",
            "2700/2700 [==============================] - 59s 22ms/step - loss: 0.7717 - accuracy: 0.7187 - val_loss: 0.7324 - val_accuracy: 0.7294\n",
            "Epoch 3/20\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.6187 - accuracy: 0.7767 - val_loss: 0.5518 - val_accuracy: 0.7976\n",
            "Epoch 4/20\n",
            "2700/2700 [==============================] - 58s 22ms/step - loss: 0.5280 - accuracy: 0.8107 - val_loss: 0.5625 - val_accuracy: 0.8013\n",
            "Epoch 5/20\n",
            "2700/2700 [==============================] - 59s 22ms/step - loss: 0.4812 - accuracy: 0.8300 - val_loss: 0.5211 - val_accuracy: 0.8091\n",
            "Epoch 6/20\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.4397 - accuracy: 0.8440 - val_loss: 0.5756 - val_accuracy: 0.7981\n",
            "Epoch 7/20\n",
            "2700/2700 [==============================] - 57s 21ms/step - loss: 0.3959 - accuracy: 0.8615 - val_loss: 0.4731 - val_accuracy: 0.8359\n",
            "Epoch 8/20\n",
            "2700/2700 [==============================] - 58s 22ms/step - loss: 0.3695 - accuracy: 0.8692 - val_loss: 0.5953 - val_accuracy: 0.7981\n",
            "Epoch 9/20\n",
            "2700/2700 [==============================] - 58s 22ms/step - loss: 0.3415 - accuracy: 0.8791 - val_loss: 0.5052 - val_accuracy: 0.8263\n",
            "Epoch 10/20\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.3258 - accuracy: 0.8853 - val_loss: 0.4517 - val_accuracy: 0.8448\n",
            "Epoch 11/20\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.2982 - accuracy: 0.8938 - val_loss: 0.5004 - val_accuracy: 0.8372\n",
            "Epoch 12/20\n",
            "2700/2700 [==============================] - 58s 22ms/step - loss: 0.2794 - accuracy: 0.9034 - val_loss: 0.5470 - val_accuracy: 0.8289\n",
            "Epoch 13/20\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.2707 - accuracy: 0.9031 - val_loss: 0.5843 - val_accuracy: 0.8144\n",
            "Epoch 14/20\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.2580 - accuracy: 0.9081 - val_loss: 0.5131 - val_accuracy: 0.8406\n",
            "Epoch 15/20\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.2360 - accuracy: 0.9197 - val_loss: 0.5418 - val_accuracy: 0.8363\n",
            "Epoch 16/20\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.2313 - accuracy: 0.9189 - val_loss: 0.4611 - val_accuracy: 0.8643\n",
            "Epoch 17/20\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.2199 - accuracy: 0.9238 - val_loss: 0.5334 - val_accuracy: 0.8467\n",
            "Epoch 18/20\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.2188 - accuracy: 0.9255 - val_loss: 0.5131 - val_accuracy: 0.8485\n",
            "Epoch 19/20\n",
            "2700/2700 [==============================] - 57s 21ms/step - loss: 0.1919 - accuracy: 0.9329 - val_loss: 0.6639 - val_accuracy: 0.8267\n",
            "Epoch 20/20\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.1895 - accuracy: 0.9349 - val_loss: 0.5560 - val_accuracy: 0.8491\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ba3745d1e40>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CNN.fit(train_data, validation_data=test_data, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6ENE066Od-yI",
        "outputId": "b48fd277-7cb7-4791-a1c7-989083be0820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.1867 - accuracy: 0.9346 - val_loss: 0.5732 - val_accuracy: 0.8487\n",
            "Epoch 2/10\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.1847 - accuracy: 0.9345 - val_loss: 0.5416 - val_accuracy: 0.8576\n",
            "Epoch 3/10\n",
            "2700/2700 [==============================] - 58s 22ms/step - loss: 0.1728 - accuracy: 0.9386 - val_loss: 0.5924 - val_accuracy: 0.8450\n",
            "Epoch 4/10\n",
            "2700/2700 [==============================] - 58s 22ms/step - loss: 0.1737 - accuracy: 0.9418 - val_loss: 0.6430 - val_accuracy: 0.8393\n",
            "Epoch 5/10\n",
            "2700/2700 [==============================] - 57s 21ms/step - loss: 0.1688 - accuracy: 0.9420 - val_loss: 0.5642 - val_accuracy: 0.8533\n",
            "Epoch 6/10\n",
            "2700/2700 [==============================] - 57s 21ms/step - loss: 0.1617 - accuracy: 0.9449 - val_loss: 0.6208 - val_accuracy: 0.8519\n",
            "Epoch 7/10\n",
            "2700/2700 [==============================] - 58s 22ms/step - loss: 0.1550 - accuracy: 0.9484 - val_loss: 0.6250 - val_accuracy: 0.8430\n",
            "Epoch 8/10\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.1543 - accuracy: 0.9470 - val_loss: 0.5742 - val_accuracy: 0.8628\n",
            "Epoch 9/10\n",
            "2700/2700 [==============================] - 58s 21ms/step - loss: 0.1486 - accuracy: 0.9510 - val_loss: 0.6347 - val_accuracy: 0.8424\n",
            "Epoch 10/10\n",
            "2700/2700 [==============================] - 57s 21ms/step - loss: 0.1421 - accuracy: 0.9525 - val_loss: 0.7363 - val_accuracy: 0.8287\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ba374723a60>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CNN.fit(train_data, validation_data=test_data, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B0G8eGHd-f5",
        "outputId": "ec6b39ef-1774-4cd8-d1c2-7be1c8a204e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/My Drive/Test/code/saved_model/my_model\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define the path to save the model\n",
        "model_save_path = '/content/drive/My Drive/Test/code/saved_model/my_model'\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
        "\n",
        "# Save the trained model\n",
        "CNN.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25uJLG4zd-Kr",
        "outputId": "8e91f411-16e5-4767-a3db-b79e31ea9003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Define the path where the model was saved\n",
        "model_save_path = '/content/drive/My Drive/Test/code/saved_model/my_model'\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = keras.models.load_model(model_save_path)\n",
        "print(\"Model loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img_path):\n",
        "    # Load the image\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=(64, 64))\n",
        "    # Convert the image to an array\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    # Rescale the image\n",
        "    img_array = img_array / 255.0\n",
        "    # Add a batch dimension\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n"
      ],
      "metadata": {
        "id": "uzlfwpBcFMUl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(model, img_path):\n",
        "  img_array = preprocess_image(img_path)\n",
        "  predictions = model.predict(img_array)\n",
        "  predicted_class = np.argmax(predictions, axis=1)\n",
        "  return predicted_class"
      ],
      "metadata": {
        "id": "LCCVeL10FN4s"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import io\n",
        "\n",
        "# Function to predict image class\n",
        "def predict_image(model, img_path):\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        img = img.resize((64, 64))  # Resize to model's input shape\n",
        "        img_array = np.array(img) / 255.0  # Normalize image\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "        predictions = model.predict(img_array)\n",
        "        predicted_class = np.argmax(predictions)\n",
        "        return predicted_class\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "        return None\n",
        "\n",
        "# Load your saved model\n",
        "model_save_path = '/content/drive/My Drive/Test/code/saved_model/my_model'\n",
        "loaded_model = keras.models.load_model(model_save_path)\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Define the direct download URL from Google Drive https://drive.google.com/file/d/1C9rkh_1uKAzAsZDza2q93UvwKAtqeUZK/view?usp=drive_link\n",
        "file_id = '1C9rkh_1uKAzAsZDza2q93UvwKAtqeUZK'  # Update with your new file ID\n",
        "new_image_url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "new_image_path = '/content/new_image.jpg'\n",
        "\n",
        "# Mapping of class indices to class names\n",
        "class_names = ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
        "\n",
        "# Download the image from URL\n",
        "response = requests.get(new_image_url, stream=True)\n",
        "if response.status_code == 200:\n",
        "    # Save the image to local path\n",
        "    with open(new_image_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(f\"Image downloaded to {new_image_path}\")\n",
        "\n",
        "    # Check if the downloaded file is a valid image\n",
        "    try:\n",
        "        img = Image.open(new_image_path)\n",
        "        img.verify()  # Verify if it's an image\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"The downloaded file is not a valid image.\")\n",
        "        exit()\n",
        "\n",
        "    # Proceed with image prediction\n",
        "    predicted_class_index = predict_image(loaded_model, new_image_path)\n",
        "    if predicted_class_index is not None:\n",
        "        predicted_class_name = class_names[predicted_class_index]\n",
        "        print(f\"Predicted class index: {predicted_class_index}\")\n",
        "        print(f\"Predicted class name: {predicted_class_name}\")\n",
        "    else:\n",
        "        print(\"Failed to predict image class.\")\n",
        "else:\n",
        "    print(f\"Failed to download image. Status code: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTouj2t0FPVj",
        "outputId": "c7d47154-181c-4bb9-88fe-01c3e87068cd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n",
            "Image downloaded to /content/new_image.jpg\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "Predicted class index: 5\n",
            "Predicted class name: Pasture\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P-Z03DLxFQ5T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}